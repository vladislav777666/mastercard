{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6e228",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Сегментация клиентов банка с использованием GMM\n",
    "#\n",
    "# Кластеризация клиентов на основе `DECENTRATHON_3.0.parquet` с использованием Gaussian Mixture Model (GMM, k=7).\n",
    "# Реализованы сегменты (Понижающийся, Повышающийся, Стабильный, Остановившийся) и атрибуты (Geo, Behavior, Category).\n",
    "# Зависимости устанавливаются автоматически без перезапуска runtime.\n",
    "# Результаты сохраняются в `segmented.parquet` с процентами сегментов и атрибутов.\n",
    "#\n",
    "# **Текущая дата и время**: 11:33:00 AM +05, Sunday, May 25, 2025\n",
    "#\n",
    "# **Запуск в Google Colab**:\n",
    "# - Загрузите `DECENTRATHON_3.0.parquet` в `/content/` или Google Drive.\n",
    "# - Выполняйте ячейки последовательно.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 0. Установка зависимостей\n",
    "\n",
    "import pkg_resources\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "requirements = \"\"\"\n",
    "pandas==2.2.2\n",
    "numpy==1.26.4\n",
    "scikit-learn==1.5.1\n",
    "matplotlib==3.9.2\n",
    "seaborn==0.13.2\n",
    "joblib==1.4.2\n",
    "onnx==1.16.2\n",
    "skl2onnx==1.16.0\n",
    "faker==28.1.0\n",
    "pyarrow==17.0.0\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "def install_requirements():\n",
    "    print(\"Проверка зависимостей...\")\n",
    "    installed = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
    "    for line in requirements.strip().split('\\n'):\n",
    "        package = line.strip()\n",
    "        if not package:\n",
    "            continue\n",
    "        pkg_name, pkg_version = package.split('==')\n",
    "        pkg_name = pkg_name.lower()\n",
    "        if pkg_name not in installed or installed[pkg_name] != pkg_version:\n",
    "            print(f\"Установка {package}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet'])\n",
    "        else:\n",
    "            print(f\"{package} уже установлен\")\n",
    "\n",
    "try:\n",
    "    install_requirements()\n",
    "    print(\"Все зависимости готовы\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка установки зависимостей: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Импорт библиотек\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(filename=\"/content/segmentation.log\", level=logging.INFO)\n",
    "faker = Faker('ru_RU')\n",
    "np.random.seed(42)\n",
    "current_datetime = datetime(2025, 5, 25, 11, 33, 0)\n",
    "print(f\"Текущая дата и время: {current_datetime.strftime('%I:%M:%S %p +05, %A, %B %d, %Y')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Загрузка данных\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print(\"Google Drive подключён\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка подключения Google Drive: {e}\")\n",
    "\n",
    "file_path = '/content/drive/MyDrive/DECENTRATHON_3.0.parquet'\n",
    "alternative_path = '/content/DECENTRATHON_3.0.parquet'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_parquet(file_path, columns=[\n",
    "            'card_id', 'transaction_timestamp', 'transaction_amount_kzt', 'merchant_mcc',\n",
    "            'transaction_type', 'acquirer_country_iso', 'merchant_city', 'wallet_type',\n",
    "            'issuer_bank_name'\n",
    "        ])\n",
    "        print(\"Данные загружены из\", file_path)\n",
    "    elif os.path.exists(alternative_path):\n",
    "        df = pd.read_parquet(alternative_path, columns=[\n",
    "            'card_id', 'transaction_timestamp', 'transaction_amount_kzt', 'merchant_mcc',\n",
    "            'transaction_type', 'acquirer_country_iso', 'merchant_city', 'wallet_type',\n",
    "            'issuer_bank_name'\n",
    "        ])\n",
    "        print(\"Данные загружены из\", alternative_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Файл не найден\")\n",
    "\n",
    "    print(f\"Размер датасета: {df.shape}\")\n",
    "    print(\"\\nПервые 5 строк:\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Файл не найден. Проверьте пути:\")\n",
    "    print(\"- Google Drive:\", file_path)\n",
    "    print(\"- Локально:\", alternative_path)\n",
    "    print(\"Действия:\")\n",
    "    print(\"1. Загрузите файл в Google Drive: /MyDrive/DECENTRATHON_3.0.parquet\")\n",
    "    print(\"2. Или перетащите файл в Colab: /content/DECENTRATHON_3.0.parquet\")\n",
    "    print(\"3. Обновите file_path, если файл в другой папке\")\n",
    "    print(\"4. Для тестирования сгенерируйте тестовый датасет:\")\n",
    "    print(\"\"\"\n",
    "    from faker import Faker\n",
    "    faker = Faker('ru_RU')\n",
    "    test_data = [{\n",
    "        'card_id': i,\n",
    "        'transaction_timestamp': faker.date_time_between(start_date='-365d', end_date='now'),\n",
    "        'transaction_amount_kzt': faker.random_int(1000, 100000),\n",
    "        'merchant_mcc': faker.random_element([3000, 5812, 5611, 7994]),\n",
    "        'transaction_type': faker.random_element(['POS', 'WEB', 'P2P']),\n",
    "        'acquirer_country_iso': faker.random_element(['KAZ', 'USA']),\n",
    "        'merchant_city': faker.city(),\n",
    "        'wallet_type': faker.random_element([None, 'Apple Pay']),\n",
    "        'issuer_bank_name': faker.company()\n",
    "    } for i in range(1000)]\n",
    "    df = pd.DataFrame(test_data)\n",
    "    df.to_parquet('/content/DECENTRATHON_3.0.parquet')\n",
    "    file_path = '/content/DECENTRATHON_3.0.parquet'\n",
    "    \"\"\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки данных: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Подготовка фичей\n",
    "\n",
    "metrics = []\n",
    "for card_id, group in df.groupby('card_id'):\n",
    "    try:\n",
    "        last_tx = group['transaction_timestamp'].max()\n",
    "        first_tx = group['transaction_timestamp'].min()\n",
    "        days_365_ago = current_datetime - timedelta(days=365)\n",
    "        days_90_ago = current_datetime - timedelta(days=90)\n",
    "        days_30_ago = current_datetime - timedelta(days=30)\n",
    "        days_60_ago = current_datetime - timedelta(days=60)\n",
    "\n",
    "        days_since_first_tx = (current_datetime - first_tx).days if pd.notnull(first_tx) else 0\n",
    "        recency_days = (current_datetime - last_tx).days if pd.notnull(last_tx) else 365\n",
    "        recent_tx = group[group['transaction_timestamp'] >= days_90_ago]\n",
    "        frequency_90d = len(recent_tx)\n",
    "        monetary_90d_kzt = recent_tx['transaction_amount_kzt'].sum() if not recent_tx.empty else 0\n",
    "        average_check_kzt = monetary_90d_kzt / frequency_90d if frequency_90d > 0 else 0\n",
    "\n",
    "        tx_0_30 = len(group[group['transaction_timestamp'] >= days_30_ago])\n",
    "        tx_30_60 = len(group[(group['transaction_timestamp'] >= days_60_ago) & \n",
    "                             (group['transaction_timestamp'] < days_30_ago)])\n",
    "        delta_count_30d = tx_0_30 - tx_30_60\n",
    "        sum_0_30 = group[group['transaction_timestamp'] >= days_30_ago]['transaction_amount_kzt'].sum() if not group[group['transaction_timestamp'] >= days_30_ago].empty else 0\n",
    "        sum_30_60 = group[(group['transaction_timestamp'] >= days_60_ago) & \n",
    "                          (group['transaction_timestamp'] < days_30_ago)]['transaction_amount_kzt'].sum() if not group[(group['transaction_timestamp'] >= days_60_ago) & (group['transaction_timestamp'] < days_30_ago)].empty else 0\n",
    "        delta_sum_30d = sum_0_30 - sum_30_60\n",
    "        avg_check_0_30 = sum_0_30 / tx_0_30 if tx_0_30 > 0 else 0\n",
    "        avg_check_30_60 = sum_30_60 / tx_30_60 if tx_30_60 > 0 else 0\n",
    "        delta_avg_check_30d = avg_check_0_30 - avg_check_30_60 if (tx_0_30 > 0 or tx_30_60 > 0) else 0\n",
    "\n",
    "        total_amount = group['transaction_amount_kzt'].sum() if not group.empty else 0\n",
    "        mcc_share_travel = group[group['merchant_mcc'].between(3000, 3299)]['transaction_amount_kzt'].sum() / total_amount if total_amount > 0 else 0\n",
    "        mcc_share_entertainment = group[group['merchant_mcc'].isin([5812, 5814])]['transaction_amount_kzt'].sum() / total_amount if total_amount > 0 else 0\n",
    "        mcc_share_fashion = group[group['merchant_mcc'].isin([5611, 5621, 5631, 5641, 5651, 5661, 5691, 5699])]['transaction_amount_kzt'].sum() / total_amount if total_amount > 0 else 0\n",
    "        mcc_share_home = group[group['merchant_mcc'].isin([5200, 5211, 5231, 5251])]['transaction_amount_kzt'].sum() / total_amount if total_amount > 0 else 0\n",
    "        mcc_share_tech = group[group['merchant_mcc'].isin([5732, 5733, 5734])]['transaction_amount_kzt'].sum() / total_amount if total_amount > 0 else 0\n",
    "        mcc_share_gaming = group[group['merchant_mcc'] == 7994]['transaction_amount_kzt'].sum() / total_amount if total_amount > 0 else 0\n",
    "\n",
    "        p2p_share = len(group[group['transaction_type'] == 'P2P']) / len(group) if len(group) > 0 else 0\n",
    "        acquirer_country_iso_share = len(group[group['acquirer_country_iso'] == 'KAZ']) / len(group) if len(group) > 0 else 0\n",
    "        merchant_city_unique = group['merchant_city'].nunique()\n",
    "        total_amount_365d = group[group['transaction_timestamp'] >= days_365_ago]['transaction_amount_kzt'].sum() if not group[group['transaction_timestamp'] >= days_365_ago].empty else 0\n",
    "        foreign_amount_365d = group[(group['transaction_timestamp'] >= days_365_ago) & \n",
    "                                    (group['acquirer_country_iso'] != 'KAZ')]['transaction_amount_kzt'].sum() if not group[(group['transaction_timestamp'] >= days_365_ago) & (group['acquirer_country_iso'] != 'KAZ')].empty else 0\n",
    "        foreign_share_365d = foreign_amount_365d / total_amount_365d if total_amount_365d > 0 else 0\n",
    "\n",
    "        if abs(monetary_90d_kzt - recent_tx['transaction_amount_kzt'].sum()) > 1e-6:\n",
    "            logging.warning(f\"Несоответствие monetary_90d_kzt для card_id {card_id}\")\n",
    "\n",
    "        metrics.append({\n",
    "            'card_id': card_id,\n",
    "            'days_since_first_tx': days_since_first_tx,\n",
    "            'recency_days': recency_days,\n",
    "            'frequency_90d': frequency_90d,\n",
    "            'monetary_90d_kzt': monetary_90d_kzt,\n",
    "            'average_check_kzt': average_check_kzt,\n",
    "            'delta_count_30d': delta_count_30d,\n",
    "            'delta_sum_30d': delta_sum_30d,\n",
    "            'delta_avg_check_30d': delta_avg_check_30d,\n",
    "            'sum_0_30': sum_0_30,\n",
    "            'sum_30_60': sum_30_60,\n",
    "            'avg_check_0_30': avg_check_0_30,\n",
    "            'avg_check_30_60': avg_check_30_60,\n",
    "            'mcc_share_travel': mcc_share_travel,\n",
    "            'mcc_share_entertainment': mcc_share_entertainment,\n",
    "            'mcc_share_fashion': mcc_share_fashion,\n",
    "            'mcc_share_home': mcc_share_home,\n",
    "            'mcc_share_tech': mcc_share_tech,\n",
    "            'mcc_share_gaming': mcc_share_gaming,\n",
    "            'p2p_share': p2p_share,\n",
    "            'acquirer_country_iso_share': acquirer_country_iso_share,\n",
    "            'merchant_city_unique': merchant_city_unique,\n",
    "            'foreign_share_365d': foreign_share_365d,\n",
    "            'issuer_bank_name': group['issuer_bank_name'].iloc[0] if not group['issuer_bank_name'].empty else \"Неизвестно\"\n",
    "        })\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка обработки card_id {card_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df['client_name'] = [faker.name() for _ in range(len(metrics_df))]\n",
    "metrics_df.to_csv('/content/metrics.csv', index=False)\n",
    "print(\"Метрики сохранены в /content/metrics.csv\")\n",
    "print(f\"Размер метрик: {metrics_df.shape}\")\n",
    "print(\"\\nПервые 5 строк метрик:\")\n",
    "display(metrics_df.head())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Присвоение атрибутов и сегментов\n",
    "\n",
    "def assign_attributes_and_segment(row):\n",
    "    geo_attr, behavior_attr, category_attr, segment_attr = None, None, None, None\n",
    "    geo_criteria, behavior_criteria, category_criteria, segment_criteria = [], [], [], []\n",
    "    \n",
    "    try:\n",
    "        # Geo Attributes\n",
    "        if row['acquirer_country_iso_share'] == 1.0:\n",
    "            geo_attr = \"Национальный\"\n",
    "            geo_criteria.append(\"acquirer_country_iso_share == 1.0\")\n",
    "        elif row['foreign_share_365d'] >= 0.01:\n",
    "            geo_attr = \"Интернациональный\"\n",
    "            geo_criteria.append(\"foreign_share_365d >= 0.01\")\n",
    "        elif row['merchant_city_unique'] == 1:\n",
    "            geo_attr = \"Местный\"\n",
    "            geo_criteria.append(\"merchant_city_unique == 1\")\n",
    "        else:\n",
    "            geo_attr = \"Неопределённый\"\n",
    "            geo_criteria.append(\"Не соответствует критериям geo\")\n",
    "\n",
    "        # Behavior Attributes\n",
    "        # Примечание: Нет данных о кредитах/просрочках. Реализовано только на основе P2P и гейминга.\n",
    "        # Если есть датасет с кредитами (например, late_payments_count), добавьте:\n",
    "        # late_payments = row['late_payments_count'] > 0  # Пример\n",
    "        if row['mcc_share_gaming'] > 0 or row['p2p_share'] > 0.3:\n",
    "            behavior_attr = \"Рискованный\"\n",
    "            behavior_criteria.append(\"mcc_share_gaming > 0 or p2p_share > 0.3\")\n",
    "        elif (row['recency_days'] <= 30 and row['delta_avg_check_30d'] >= 0 and \n",
    "              row['p2p_share'] == 0):\n",
    "            behavior_attr = \"Звездный\"\n",
    "            behavior_criteria.append(\"recency_days <= 30 and delta_avg_check_30d >= 0 and p2p_share == 0\")\n",
    "        else:\n",
    "            behavior_attr = \"Стандартный\"\n",
    "            behavior_criteria.append(\"Не соответствует критериям behavior\")\n",
    "\n",
    "        # Category Attributes\n",
    "        if row['mcc_share_travel'] >= 0.3:\n",
    "            category_attr = \"Любитель путешествий\"\n",
    "            category_criteria.append(\"mcc_share_travel >= 0.3\")\n",
    "        elif row['mcc_share_entertainment'] >= 0.3:\n",
    "            category_attr = \"Гастроном\"\n",
    "            category_criteria.append(\"mcc_share_entertainment >= 0.3\")\n",
    "        elif row['mcc_share_fashion'] >= 0.3:\n",
    "            category_attr = \"Модник\"\n",
    "            category_criteria.append(\"mcc_share_fashion >= 0.3\")\n",
    "        elif row['mcc_share_home'] >= 0.3:\n",
    "            category_attr = \"Домосед\"\n",
    "            category_criteria.append(\"mcc_share_home >= 0.3\")\n",
    "        elif row['mcc_share_tech'] >= 0.3:\n",
    "            category_attr = \"Техногик\"\n",
    "            category_criteria.append(\"mcc_share_tech >= 0.3\")\n",
    "        elif row['mcc_share_gaming'] >= 0.3:\n",
    "            category_attr = \"Геймер\"\n",
    "            category_criteria.append(\"mcc_share_gaming >= 0.3\")\n",
    "        else:\n",
    "            category_attr = \"Стандартный\"\n",
    "            category_criteria.append(\"Все mcc_share < 0.3\")\n",
    "\n",
    "        # Segments\n",
    "        if row['avg_check_0_30'] == 0:\n",
    "            segment_attr = \"Остановившийся\"\n",
    "            segment_criteria.append(\"avg_check_0_30 == 0\")\n",
    "        elif row['avg_check_0_30'] < row['avg_check_30_60'] and row['avg_check_30_60'] > 0:\n",
    "            segment_attr = \"Понижающийся\"\n",
    "            segment_criteria.append(\"avg_check_0_30 < avg_check_30_60\")\n",
    "        elif row['sum_0_30'] > row['sum_30_60']:\n",
    "            segment_attr = \"Повышающийся\"\n",
    "            segment_criteria.append(\"sum_0_30 > sum_30_60\")\n",
    "        elif row['sum_30_60'] > 0 and abs(row['sum_0_30'] - row['sum_30_60']) / row['sum_30_60'] < 0.1:\n",
    "            segment_attr = \"Стабильный\"\n",
    "            segment_criteria.append(\"abs(sum_0_30 - sum_30_60) / sum_30_60 < 0.1\")\n",
    "        else:\n",
    "            segment_attr = \"Неопределённый\"\n",
    "            segment_criteria.append(\"Не соответствует критериям сегмента\")\n",
    "\n",
    "    except Exception as e:\n",
    "        geo_criteria.append(f\"Ошибка в geo: {e}\")\n",
    "        behavior_criteria.append(f\"Ошибка в behavior: {e}\")\n",
    "        category_criteria.append(f\"Ошибка в category: {e}\")\n",
    "        segment_criteria.append(f\"Ошибка в segment: {e}\")\n",
    "        geo_attr = behavior_attr = category_attr = segment_attr = \"Неопределённый\"\n",
    "\n",
    "    return (geo_attr, behavior_attr, category_attr, segment_attr,\n",
    "            geo_criteria, behavior_criteria, category_criteria, segment_criteria)\n",
    "\n",
    "metrics_df[['geo_attribute', 'behavior_attribute', 'category_attribute', 'segment_attribute',\n",
    "            'geo_criteria', 'behavior_criteria', 'category_criteria', 'segment_criteria']] = metrics_df.apply(assign_attributes_and_segment, axis=1, result_type='expand')\n",
    "\n",
    "# Проценты атрибутов и сегментов\n",
    "total_clients = len(metrics_df)\n",
    "attribute_stats = {\n",
    "    'geo': metrics_df['geo_attribute'].value_counts(normalize=True) * 100,\n",
    "    'behavior': metrics_df['behavior_attribute'].value_counts(normalize=True) * 100,\n",
    "    'category': metrics_df['category_attribute'].value_counts(normalize=True) * 100,\n",
    "    'segment': metrics_df['segment_attribute'].value_counts(normalize=True) * 100\n",
    "}\n",
    "attribute_stats_df = pd.DataFrame({\n",
    "    'Attribute': ['geo_' + k for k in attribute_stats['geo'].index] + \n",
    "                 ['behavior_' + k for k in attribute_stats['behavior'].index] + \n",
    "                 ['category_' + k for k in attribute_stats['category'].index] + \n",
    "                 ['segment_' + k for k in attribute_stats['segment'].index],\n",
    "    'Percent': list(attribute_stats['geo'].values) + \n",
    "               list(attribute_stats['behavior'].values) + \n",
    "               list(attribute_stats['category'].values) + \n",
    "               list(attribute_stats['segment'].values)\n",
    "})\n",
    "attribute_stats_df.to_csv('/content/attribute_stats.csv', index=False)\n",
    "print(\"Процентное распределение атрибутов и сегментов:\")\n",
    "display(attribute_stats_df)\n",
    "\n",
    "conditions_data = [\n",
    "    {\"Тип\": \"Geo Attribute\", \"Название\": \"Национальный\", \"Условие\": \"acquirer_country_iso_share == 1.0\"},\n",
    "    {\"Тип\": \"Geo Attribute\", \"Название\": \"Интернациональный\", \"Условие\": \"foreign_share_365d >= 0.01\"},\n",
    "    {\"Тип\": \"Geo Attribute\", \"Название\": \"Местный\", \"Условие\": \"merchant_city_unique == 1\"},\n",
    "    {\"Тип\": \"Geo Attribute\", \"Название\": \"Неопределённый\", \"Условие\": \"Не соответствует критериям geo\"},\n",
    "    {\"Тип\": \"Behavior Attribute\", \"Название\": \"Рискованный\", \"Условие\": \"mcc_share_gaming > 0 or p2p_share > 0.3 (данные о кредитах отсутствуют)\"},\n",
    "    {\"Тип\": \"Behavior Attribute\", \"Название\": \"Звездный\", \"Условие\": \"recency_days <= 30 and delta_avg_check_30d >= 0 and p2p_share == 0 (данные о кредитах отсутствуют)\"},\n",
    "    {\"Тип\": \"Behavior Attribute\", \"Название\": \"Стандартный\", \"Условие\": \"Не соответствует критериям behavior\"},\n",
    "    {\"Тип\": \"Behavior Attribute\", \"Название\": \"Неопределённый\", \"Условие\": \"Ошибка или недостаток данных\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Любитель путешествий\", \"Условие\": \"mcc_share_travel >= 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Гастроном\", \"Условие\": \"mcc_share_entertainment >= 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Модник\", \"Условие\": \"mcc_share_fashion >= 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Домосед\", \"Условие\": \"mcc_share_home >= 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Техногик\", \"Условие\": \"mcc_share_tech >= 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Геймер\", \"Условие\": \"mcc_share_gaming >= 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Стандартный\", \"Условие\": \"Все mcc_share < 0.3\"},\n",
    "    {\"Тип\": \"Category Attribute\", \"Название\": \"Неопределённый\", \"Условие\": \"Ошибка или недостаток данных\"},\n",
    "    {\"Тип\": \"Segment Attribute\", \"Название\": \"Понижающийся\", \"Условие\": \"avg_check_0_30 < avg_check_30_60 and avg_check_30_60 > 0\"},\n",
    "    {\"Тип\": \"Segment Attribute\", \"Название\": \"Повышающийся\", \"Условие\": \"sum_0_30 > sum_30_60\"},\n",
    "    {\"Тип\": \"Segment Attribute\", \"Название\": \"Стабильный\", \"Условие\": \"abs(sum_0_30 - sum_30_60) / sum_30_60 < 0.1 and sum_30_60 > 0\"},\n",
    "    {\"Тип\": \"Segment Attribute\", \"Название\": \"Остановившийся\", \"Условие\": \"avg_check_0_30 == 0\"},\n",
    "    {\"Тип\": \"Segment Attribute\", \"Название\": \"Неопределённый\", \"Условие\": \"Не соответствует критериям сегмента\"}\n",
    "]\n",
    "\n",
    "conditions_df = pd.DataFrame(conditions_data)\n",
    "conditions_df.to_csv(\"/content/conditions.csv\", index=False)\n",
    "print(\"Таблица условий сохранена как /content/conditions.csv\")\n",
    "display(conditions_df)\n",
    "\n",
    "print(\"\\nПервые 5 строк с атрибутами и сегментами:\")\n",
    "display(metrics_df[['card_id', 'geo_attribute', 'behavior_attribute', 'category_attribute', 'segment_attribute']].head())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Стандартизация фичей\n",
    "\n",
    "numeric_cols = [\n",
    "    'days_since_first_tx', 'recency_days', 'frequency_90d', 'monetary_90d_kzt', 'average_check_kzt',\n",
    "    'delta_count_30d', 'delta_sum_30d', 'delta_avg_check_30d', 'mcc_share_travel', 'mcc_share_entertainment',\n",
    "    'mcc_share_fashion', 'mcc_share_home', 'mcc_share_tech', 'mcc_share_gaming', 'p2p_share',\n",
    "    'acquirer_country_iso_share', 'merchant_city_unique', 'foreign_share_365d'\n",
    "]\n",
    "\n",
    "try:\n",
    "    features = metrics_df[numeric_cols].fillna(metrics_df[numeric_cols].median())\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(features)\n",
    "    joblib.dump(scaler, \"/content/scaler.pkl\")\n",
    "    print(\"StandardScaler сохранён как /content/scaler.pkl\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при стандартизации фичей: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Подбор числа компонент для GMM\n",
    "\n",
    "bic_scores = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    try:\n",
    "        gmm = GaussianMixture(n_components=k, covariance_type='full', init_params='kmeans', max_iter=300, random_state=42)\n",
    "        gmm.fit(X_scaled)\n",
    "        bic_scores.append(gmm.bic(X_scaled))\n",
    "        labels = gmm.predict(X_scaled)\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "        silhouette_scores.append(score)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при GMM для k={k}: {e}\")\n",
    "        continue\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_range, bic_scores, \"bo-\")\n",
    "plt.xlabel(\"Число компонент (k)\")\n",
    "plt.ylabel(\"BIC\")\n",
    "plt.title(\"BIC для выбора k в GMM\")\n",
    "plt.savefig(\"/content/bic_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_range, silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"Число компонент (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score для выбора k в GMM\")\n",
    "plt.savefig(\"/content/silhouette_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. GMM кластеризация\n",
    "\n",
    "optimal_k = 7\n",
    "try:\n",
    "    gmm = GaussianMixture(n_components=optimal_k, covariance_type='full', init_params='kmeans', max_iter=300, random_state=42)\n",
    "    metrics_df['gmm_cluster'] = gmm.fit_predict(X_scaled)\n",
    "\n",
    "    silhouette = silhouette_score(X_scaled, metrics_df['gmm_cluster'])\n",
    "    print(f\"BIC: {gmm.bic(X_scaled):.2f}\")\n",
    "    print(f\"Silhouette Score: {silhouette:.2f}\")\n",
    "    logging.info(f\"BIC: {gmm.bic(X_scaled):.2f}, Silhouette Score: {silhouette:.2f}\")\n",
    "\n",
    "    initial_types = [(\"input\", FloatTensorType([None, X_scaled.shape[1]]))]\n",
    "    onnx_model = convert_sklearn(gmm, initial_types=initial_types, target_opset=11)\n",
    "    onnx.save_model(onnx_model, \"/content/client_segmentation.onnx\")\n",
    "    print(\"Модель экспортирована в /content/client_segmentation.onnx\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при кластеризации: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Анализ кластеров и сегментов\n",
    "\n",
    "try:\n",
    "    cluster_stats = metrics_df.groupby('gmm_cluster').agg({\n",
    "        'card_id': 'count',\n",
    "        **{col: 'mean' for col in numeric_cols},\n",
    "        'geo_attribute': lambda x: x.mode()[0] if not x.empty else \"Неизвестно\",\n",
    "        'behavior_attribute': lambda x: x.mode()[0] if not x.empty else \"Неизвестно\",\n",
    "        'category_attribute': lambda x: x.mode()[0] if not x.empty else \"Неизвестно\",\n",
    "        'segment_attribute': lambda x: x.mode()[0] if not x.empty else \"Неизвестно\",\n",
    "        'issuer_bank_name': lambda x: x.mode()[0] if not x.empty else \"Неизвестно\",\n",
    "        'client_name': lambda x: x.iloc[0] if not x.empty else \"Неизвестно\"\n",
    "    }).reset_index()\n",
    "\n",
    "    cluster_stats['percent'] = cluster_stats['card_id'] / cluster_stats['card_id'].sum() * 100\n",
    "    cluster_stats = cluster_stats.rename(columns={'card_id': 'client_count'})\n",
    "    print(\"Характеристики кластеров:\")\n",
    "    display(cluster_stats.round(2))\n",
    "\n",
    "    cluster_stats.to_csv(\"/content/cluster_stats.csv\", index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при анализе кластеров: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Визуализация кластеров\n",
    "\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=X_scaled[:, numeric_cols.index('recency_days')], \n",
    "                    y=X_scaled[:, numeric_cols.index('monetary_90d_kzt')], \n",
    "                    hue=metrics_df['gmm_cluster'], palette=\"deep\")\n",
    "    plt.xlabel('recency_days (scaled)')\n",
    "    plt.ylabel('monetary_90d_kzt (scaled)')\n",
    "    plt.title(\"Визуализация GMM кластеров\")\n",
    "    plt.savefig(\"/content/cluster_visualization.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при визуализации кластеров: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Data Dictionary\n",
    "\n",
    "data_dict = [\n",
    "    {\"Название поля\": \"card_id\", \"Тип данных\": \"Int64\", \"Формула/Источник\": \"Уникальный идентификатор клиента/карты.\"},\n",
    "    {\"Название поля\": \"transaction_timestamp\", \"Тип данных\": \"datetime64[us]\", \"Формула/Источник\": \"Временная метка транзакции.\"},\n",
    "    {\"Название поля\": \"issuer_bank_name\", \"Тип данных\": \"object\", \"Формула/Источник\": \"Название банка-эмитента.\"},\n",
    "    {\"Название поля\": \"merchant_mcc\", \"Тип данных\": \"Int64\", \"Формула/Источник\": \"Код категории мерчанта (MCC).\"},\n",
    "    {\"Название поля\": \"merchant_city\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Город мерчанта.\"},\n",
    "    {\"Название поля\": \"transaction_type\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Тип транзакции (например, 'POS', 'WEB', 'P2P').\"},\n",
    "    {\"Название поля\": \"transaction_amount_kzt\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"Сумма транзакции в тенге (KZT).\"},\n",
    "    {\"Название поля\": \"acquirer_country_iso\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Код страны эквайера (например, 'KAZ').\"},\n",
    "    {\"Название поля\": \"wallet_type\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Тип кошелька (например, 'Apple Pay').\"},\n",
    "    {\"Название поля\": \"days_since_first_tx\", \"Тип данных\": \"int64\", \"Формула/Источник\": \"(current_date - MIN(transaction_timestamp)).days\"},\n",
    "    {\"Название поля\": \"recency_days\", \"Тип данных\": \"int64\", \"Формула/Источник\": \"(current_date - MAX(transaction_timestamp)).days\"},\n",
    "    {\"Название поля\": \"frequency_90d\", \"Тип данных\": \"int64\", \"Формула/Источник\": \"COUNT(transaction_id WHERE transaction_timestamp >= current_date - 90 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"monetary_90d_kzt\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(transaction_amount_kzt WHERE transaction_timestamp >= current_date - 90 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"average_check_kzt\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"monetary_90d_kzt / frequency_90d, 0 если frequency_90d = 0\"},\n",
    "    {\"Название поля\": \"delta_count_30d\", \"Тип данных\": \"int64\", \"Формула/Источник\": \"COUNT(0–30 days) - COUNT(30–60 days)\"},\n",
    "    {\"Название поля\": \"delta_sum_30d\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(0–30 days) - SUM(30–60 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"delta_avg_check_30d\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"AVG(0–30 days) - AVG(30–60 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"sum_0_30\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(transaction_amount_kzt WHERE transaction_timestamp >= current_date - 30 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"sum_30_60\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(transaction_amount_kzt WHERE transaction_timestamp BETWEEN current_date - 60 days AND current_date - 30 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"avg_check_0_30\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"sum_0_30 / COUNT(0–30 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"avg_check_30_60\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"sum_30_60 / COUNT(30–60 days), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"mcc_share_travel\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(MCC 3000–3299) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"mcc_share_entertainment\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(MCC 5812, 5814) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"mcc_share_fashion\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(MCC 5611, 5621, 5631, 5641, 5651, 5661, 5691, 5699) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"mcc_share_home\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(MCC 5200, 5211, 5231, 5251) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"mcc_share_tech\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(MCC 5732–5734) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"mcc_share_gaming\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(MCC 7994) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"p2p_share\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"COUNT(transaction_type = 'P2P') / COUNT(*), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"acquirer_country_iso_share\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"COUNT(acquirer_country_iso = 'KAZ') / COUNT(*), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"merchant_city_unique\", \"Тип данных\": \"int64\", \"Формула/Источник\": \"COUNT(DISTINCT merchant_city)\"},\n",
    "    {\"Название поля\": \"foreign_share_365d\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"SUM(transaction_amount_kzt WHERE acquirer_country_iso != 'KAZ' AND transaction_timestamp >= current_date - 365 days) / SUM(transaction_amount_kzt), 0 если нет транзакций\"},\n",
    "    {\"Название поля\": \"gmm_cluster\", \"Тип данных\": \"int32\", \"Формула/Источник\": \"Номер кластера (0–6) из GMM\"},\n",
    "    {\"Название поля\": \"geo_attribute\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Национальный (acquirer_country_iso_share == 1.0), Интернациональный (foreign_share_365d >= 0.01), Местный (merchant_city_unique == 1), Неопределённый (иначе)\"},\n",
    "    {\"Название поля\": \"behavior_attribute\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Рискованный (mcc_share_gaming > 0 or p2p_share > 0.3), Звездный (recency_days <= 30 and delta_avg_check_30d >= 0 and p2p_share == 0), Стандартный (иначе), Неопределённый (ошибка)\"},\n",
    "    {\"Название поля\": \"category_attribute\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Любитель путешествий (mcc_share_travel >= 0.3), Гастроном (mcc_share_entertainment >= 0.3), Модник (mcc_share_fashion >= 0.3), Домосед (mcc_share_home >= 0.3), Техногик (mcc_share_tech >= 0.3), Геймер (mcc_share_gaming >= 0.3), Стандартный (все mcc_share < 0.3), Неопределённый (ошибка)\"},\n",
    "    {\"Название поля\": \"segment_attribute\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Понижающийся (avg_check_0_30 < avg_check_30_60 and avg_check_30_60 > 0), Повышающийся (sum_0_30 > sum_30_60), Стабильный (abs(sum_0_30 - sum_30_60) / sum_30_60 < 0.1 and sum_30_60 > 0), Остановившийся (avg_check_0_30 == 0), Неопределённый (иначе)\"},\n",
    "    {\"Название поля\": \"geo_criteria\", \"Тип данных\": \"object\", \"Формула/Источник\": \"Критерии присвоения geo_attribute\"},\n",
    "    {\"Название поля\": \"behavior_criteria\", \"Тип данных\": \"object\", \"Формула/Источник\": \"Критерии присвоения behavior_attribute\"},\n",
    "    {\"Название поля\": \"category_criteria\", \"Тип данных\": \"object\", \"Формула/Источник\": \"Критерии присвоения category_attribute\"},\n",
    "    {\"Название поля\": \"segment_criteria\", \"Тип данных\": \"object\", \"Формула/Источник\": \"Критерии присвоения segment_attribute\"},\n",
    "    {\"Название поля\": \"client_name\", \"Тип данных\": \"string\", \"Формула/Источник\": \"Сгенерированное ФИО (Faker)\"},\n",
    "    {\"Название поля\": \"attribute_percent\", \"Тип данных\": \"Float64\", \"Формула/Источник\": \"Процент клиентов с данным атрибутом/сегментом: client_count / total_clients * 100 (см. attribute_stats.csv)\"}\n",
    "]\n",
    "\n",
    "try:\n",
    "    data_dict_df = pd.DataFrame(data_dict)\n",
    "    data_dict_df.to_csv(\"/content/data_dictionary.csv\", index=False, encoding='utf-8')\n",
    "    print(\"Data Dictionary сохранён как /content/data_dictionary.csv\")\n",
    "    display(data_dict_df)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при создании Data Dictionary: {e}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Результаты сегментации\n",
    "\n",
    "try:\n",
    "    result_df = metrics_df[['card_id', 'gmm_cluster', 'geo_attribute', 'behavior_attribute', \n",
    "                           'category_attribute', 'segment_attribute', 'geo_criteria', \n",
    "                           'behavior_criteria', 'category_criteria', 'segment_criteria',\n",
    "                           'client_name', 'issuer_bank_name']]\n",
    "    result_df.to_parquet(\"/content/segmented.parquet\", index=False)\n",
    "    print(\"Результаты сегментации сохранены как /content/segmented.parquet\")\n",
    "    print(\"\\nПервые 5 строк результатов:\")\n",
    "    display(result_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении результатов: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
